{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d861a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/env_NLP/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast, \n",
    "    DistilBertConfig,\n",
    "    DistilBertModel,\n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3016c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LR = 1e-5\n",
    "EPOCHS = 3\n",
    "MODEL_PATH_1 = \"ag_news_distilbert_finetuned\"\n",
    "MODEL_PATH_2 = \"ag_news_distilbert_soft\"\n",
    "MODEL_PATH_3 = \"ag_news_distilbert_hard\"\n",
    "MAX_LENGTH = 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a5e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## device\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.backends.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "# DEVICE = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63952b36",
   "metadata": {},
   "source": [
    "### phase 1: finetune the model on ag_news dataset for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6edcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, tokenizer, batch_size,  max_length=MAX_LENGTH,size=None):\n",
    "    # if size is None:\n",
    "    #     dataset = load_dataset(dataset_name, split=split)\n",
    "    # else:\n",
    "    #     dataset = load_dataset(dataset_name, split=split).shuffle(seed=42).select(range(size))\n",
    "    def preprocess(examples):\n",
    "        enc = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=max_length)\n",
    "        enc['labels'] = examples['label']\n",
    "        return enc\n",
    "    dataset = dataset.map(preprocess, batched=True)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    # return DataLoader(dataset, batch_size=batch_size, shuffle=(split=='train'))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332299b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    # Extract logits\n",
    "    logits = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # Get predicted class labels\n",
    "    preds = logits.argmax(-1)\n",
    "    \n",
    "    # True labels\n",
    "    labels = pred.label_ids\n",
    "    \n",
    "    # Use macro average for multi-class classification\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    print(f'accuracy: {acc:.4f}, f1: {f1:.4f}, precision: {precision:.4f}, recall: {recall:.4f}')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4896101",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9af57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ag_news_dataset = get_dataloader('ag_news', tokenizer,  32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da8e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ag_news_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9784a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n,batch in enumerate(ag_news_dataset):\n",
    "#     print(batch)\n",
    "#     if n==0:\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e60b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration and enable output_attentions\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
    "\n",
    "# Load the model with the configuration\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',config=config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d104eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b481ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting training and validation and testing datasets\n",
    "\n",
    "# Load the full training dataset\n",
    "full_train_dataset = load_dataset('ag_news', split='train').shuffle(seed=42)\n",
    "\n",
    "# Split the training dataset into train and validation sets\n",
    "train_size = 0.9  # 90% for training, 10% for validation\n",
    "split_data = full_train_dataset.train_test_split(test_size=1-train_size, seed=42)\n",
    "train_data = split_data['train']\n",
    "val_data = split_data['test']\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = load_dataset('ag_news', split='test')\n",
    "\n",
    "full_train_dataset, \n",
    "\n",
    "# # Preprocess train, validation, and test datasets\n",
    "train_dataset = preprocess_data(train_data, tokenizer, BATCH_SIZE)\n",
    "val_dataset = preprocess_data(val_data, tokenizer, BATCH_SIZE)\n",
    "test_dataset = preprocess_data(test_data, tokenizer, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a430d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c91c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,  # Set to True if you want to push to Hugging Face Hub\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516a0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065aae4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6750' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6750/6750 2:05:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.168960</td>\n",
       "      <td>0.943917</td>\n",
       "      <td>0.943718</td>\n",
       "      <td>0.944022</td>\n",
       "      <td>0.943722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9439, f1: 0.9437, precision: 0.9440, recall: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6750, training_loss=0.24621473896944965, metrics={'train_runtime': 7537.8846, 'train_samples_per_second': 14.328, 'train_steps_per_second': 0.895, 'total_flos': 1.4306989326336e+16, 'train_loss': 0.24621473896944965, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a47c0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ag_news_distilbert_finetuned\n"
     ]
    }
   ],
   "source": [
    "model_path = MODEL_PATH_1\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13896dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9439, f1: 0.9437, precision: 0.9440, recall: 0.9437\n",
      "Evaluation results: {'eval_loss': 0.16896000504493713, 'eval_accuracy': 0.9439166666666666, 'eval_f1': 0.9437184414294727, 'eval_precision': 0.9440216453956681, 'eval_recall': 0.9437220356104892, 'eval_runtime': 216.7268, 'eval_samples_per_second': 55.369, 'eval_steps_per_second': 6.921, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99447db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample news: 'The stock market saw a significant drop after the Fed's announcement on interest rates.'\n",
      "Predicted topic: Business\n"
     ]
    }
   ],
   "source": [
    "# AG News class labels\n",
    "LABELS = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "# Example inference function for AG News\n",
    "def predict_topic(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH, padding=\"max_length\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    return LABELS[predicted_class]\n",
    "\n",
    "# Test with a sample news text\n",
    "sample_text = \"The stock market saw a significant drop after the Fed's announcement on interest rates.\"\n",
    "predicted_topic = predict_topic(sample_text)\n",
    "\n",
    "print(f\"Sample news: '{sample_text}'\")\n",
    "print(f\"Predicted topic: {predicted_topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73981bf",
   "metadata": {},
   "source": [
    "### phase 2: soft pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7076fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bz2 import compress\n",
    "class ThresholdLayer(nn.Module):\n",
    "    \"\"\"Layer that learns threshold values for attention-based token pruning\"\"\"\n",
    "    def __init__(self, num_layers, init_threshold=0.02):\n",
    "        super(ThresholdLayer, self).__init__()\n",
    "        self.thresholds = nn.Parameter(torch.ones(num_layers) * init_threshold)\n",
    "        \n",
    "    def forward(self, layer_idx):\n",
    "        return self.thresholds[layer_idx]\n",
    "\n",
    "class DistilBertWithThresholdPruning(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_labels=4, temperature=1e-3, init_threshold=0.01, lambda_reg=1e-5):\n",
    "        super(DistilBertWithThresholdPruning, self).__init__()\n",
    "        \n",
    "        # Load the fine-tuned DistilBERT model\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\n",
    "            pretrained_model_path, \n",
    "            output_attentions=True,  # Important to get attention scores\n",
    "            attn_implementation='eager',  # Use softmax for attention\n",
    "        )\n",
    "        \n",
    "        # Number of transformer layers in DistilBERT\n",
    "        self.num_layers = len(self.distilbert.transformer.layer)\n",
    "        \n",
    "        # Create the threshold layer\n",
    "        self.threshold_layer = ThresholdLayer(\n",
    "            num_layers=self.num_layers,\n",
    "            init_threshold=init_threshold\n",
    "        )\n",
    "        \n",
    "        # Temperature for sigmoid scaling\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Regularization coefficient\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "        # Classification head\n",
    "        self.pre_classifier = nn.Linear(768, 768)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "        \n",
    "\n",
    "    \n",
    "    def prune_tokens(self, hidden_states,  attn_mask):\n",
    "        \"\"\"Apply token pruning based on attention mask\"\"\"\n",
    "        # For training phase: soft masking using the attention scores\n",
    "        # We multiply by the mask which will downweight less important tokens\n",
    "        # hidden_states: [batch_size, seq_len, hidden_size]\n",
    "        # attn_mask: [batch_size, seq_len]\n",
    "        \n",
    "        # Expand mask to match hidden states dimensions\n",
    "        expanded_mask = attn_mask.unsqueeze(-1).expand_as(hidden_states)\n",
    "        \n",
    "        # Apply mask to hidden states\n",
    "        masked_hidden_states = hidden_states * expanded_mask\n",
    "        \n",
    "        return masked_hidden_states\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Get DistilBERT outputs with attention scores\n",
    "        outputs = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=True,  # Important to get attention scores\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Get sequence output and attention scores\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "        attention_outputs = outputs.attentions  # Tuple of tensors [batch_size, num_heads, seq_len, seq_len]\n",
    "        \n",
    "        # Apply pruning using attention scores\n",
    "        reg_loss = 0.0\n",
    "        \n",
    "        # Process each layer's attention\n",
    "        for layer_idx, attention in enumerate(attention_outputs):\n",
    "            # Average attention scores across heads to get token importance\n",
    "            # [batch_size, seq_len, seq_len] -> [batch_size, seq_len]\n",
    "            token_scores = attention.mean(dim=1).mean(dim=1)  \n",
    "            \n",
    "            # Get threshold for this layer\n",
    "            threshold = self.threshold_layer(layer_idx)\n",
    "            \n",
    "            # Create soft mask\n",
    "            soft_mask = torch.sigmoid((token_scores - threshold) / self.temperature)\n",
    "            \n",
    "            # Add regularization: encourage fewer retained tokens\n",
    "            reg_loss += soft_mask.mean()\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Use [CLS] token for classification (first token)\n",
    "        pooled_output = sequence_output[:, 0]  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Classification head\n",
    "        pooled_output = self.pre_classifier(pooled_output)\n",
    "        pooled_output = nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "            loss += self.lambda_reg * reg_loss\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )\n",
    "\n",
    "    def fix_thresholds(self):\n",
    "        \"\"\"Fix the threshold values after training\"\"\"\n",
    "        self.threshold_layer.thresholds.requires_grad = False\n",
    "        \n",
    "    def get_thresholds(self):\n",
    "        \"\"\"Get the learned threshold values for each layer\"\"\"\n",
    "        return self.threshold_layer.thresholds.detach().cpu().numpy()\n",
    "    \n",
    "    def save_pretrained(self, save_directory):\n",
    "        \"\"\"Save model to the specified directory in a format compatible with HF\"\"\"\n",
    "        if not os.path.exists(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "        \n",
    "        # Save the model weights\n",
    "        torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "        \n",
    "        # Save configuration\n",
    "        config = {\n",
    "            \"model_type\": \"distilbert\",\n",
    "            \"num_labels\": 4,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"thresholds\": self.get_thresholds().tolist(),\n",
    "            \"num_layers\": self.num_layers,\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(save_directory, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_path, num_labels=4, temperature=1e-3, init_threshold=0.01, lambda_reg=1e-5):\n",
    "        \"\"\"Load model from pretrained directory\"\"\"\n",
    "        # Load config from saved model\n",
    "        config_path = os.path.join(pretrained_model_path, \"config.json\")\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "            \n",
    "            # Get parameters from config\n",
    "            # init_threshold = 0.01  # default\n",
    "             # Get parameters from config\n",
    "            init_threshold = config.get(\"thresholds\", [init_threshold])[0]\n",
    "            num_labels = config.get(\"num_labels\", num_labels)\n",
    "            temperature = config.get(\"temperature\", temperature)\n",
    "            \n",
    "        \n",
    "        # Create a new instance\n",
    "        model = cls(\n",
    "            pretrained_model_path,\n",
    "            num_labels=num_labels,\n",
    "            temperature=temperature,\n",
    "            init_threshold=init_threshold,\n",
    "            lambda_reg=lambda_reg\n",
    "        )\n",
    "        \n",
    "        # Load the state dict if it exists\n",
    "        model_path = os.path.join(pretrained_model_path, \"pytorch_model.bin\")\n",
    "        if os.path.exists(model_path):\n",
    "            model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091febcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regex import B\n",
    "\n",
    "\n",
    "def train_threshold_model(pretrained_model_path, dataset, tokenizer):\n",
    "    \"\"\"Train the threshold-based model\"\"\"\n",
    "    # Create model\n",
    "    model = DistilBertWithThresholdPruning(\n",
    "        pretrained_model_path=pretrained_model_path,\n",
    "        num_labels=4,\n",
    "        temperature=1e-3,\n",
    "        init_threshold=0.02,\n",
    "        lambda_reg=1e-5\n",
    "    )\n",
    "    \n",
    "    # Training parameters\n",
    "    learning_rate = 1e-5\n",
    "    num_epochs = 1\n",
    "    batch_size = BATCH_SIZE\n",
    "    device = DEVICE\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create DataLoader for training set\n",
    "    train_dataloader = train_dataset\n",
    "    \n",
    "    torch.mps.empty_cache()\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            # Prepare batch\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "             # Clear attention scores to free memory\n",
    "            del outputs.attentions\n",
    "            torch.mps.empty_cache()  # Clear memory on MPS backend\n",
    "\n",
    "            \n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Avg loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Fix thresholds after training\n",
    "    model.fix_thresholds()\n",
    "    \n",
    "    # Print learned thresholds\n",
    "    thresholds = model.get_thresholds()\n",
    "    print(f\"Learned thresholds: {thresholds}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db14558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Avg loss: 0.1589\n",
      "Learned thresholds: [0.07640352 0.09950283 0.08569011 0.06723312 0.12944147 0.19382311]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Path to your fine-tuned model from previous step\n",
    "pretrained_model_path = MODEL_PATH_1\n",
    "\n",
    "# Train threshold model\n",
    "threshold_model = train_threshold_model(\n",
    "    pretrained_model_path=pretrained_model_path,\n",
    "    dataset=train_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9fd8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_model.save_pretrained(MODEL_PATH_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78874f",
   "metadata": {},
   "source": [
    "### phase 3: fixing thresholds and training for hard pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "664a00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertWithHardPruning(nn.Module):\n",
    "    def __init__(self, pretrained_soft_model: DistilBertWithThresholdPruning):\n",
    "        super().__init__()\n",
    "\n",
    "        # Clone the architecture and load soft-pruned weights\n",
    "        self.distilbert = pretrained_soft_model.distilbert\n",
    "        self.num_layers = pretrained_soft_model.num_layers\n",
    "        self.threshold_layer = pretrained_soft_model.threshold_layer  # frozen\n",
    "        self.temperature = pretrained_soft_model.temperature\n",
    "        self.pre_classifier = pretrained_soft_model.pre_classifier\n",
    "        self.dropout = pretrained_soft_model.dropout\n",
    "        self.classifier = pretrained_soft_model.classifier\n",
    "\n",
    "        # Freeze thresholds\n",
    "        self.threshold_layer.thresholds.requires_grad = False\n",
    "\n",
    "        # self.\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state  # [B, S, H]\n",
    "        attention_outputs = outputs.attentions \n",
    "        for layer_idx, attention in enumerate(attention_outputs):\n",
    "            \n",
    "            token_scores = attention.mean(dim=1).mean(dim=1)  # [B, seq_len]\n",
    "            threshold = self.threshold_layer(layer_idx)\n",
    "            hard_mask = (token_scores > threshold).float()  # binary mask\n",
    "            # print(\"Hard mask shape:\", hard_mask.shape)\n",
    "\n",
    "            # Always keep [CLS] token (position 0)\n",
    "            cls_token = torch.ones(hard_mask.size(0), 1, device=hard_mask.device)\n",
    "            hard_mask = torch.cat([cls_token, hard_mask[:, 1:]], dim=1)\n",
    "\n",
    "            # Expand and apply pruning mask\n",
    "            expanded_mask = hard_mask.unsqueeze(-1).expand_as(hidden_states)\n",
    "            hidden_states = hidden_states * expanded_mask\n",
    "\n",
    "        pooled_output = hidden_states[:, 0]  # Use CLS token for classification\n",
    "        pooled_output = self.pre_classifier(pooled_output)\n",
    "        pooled_output = nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )\n",
    "            \n",
    "    \n",
    "    def save_pretrained(self, save_directory):\n",
    "       \n",
    "        if not os.path.exists(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "\n",
    "        # Save model state dict\n",
    "        torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "\n",
    "        # Save thresholds (frozen from soft model)\n",
    "        thresholds = self.threshold_layer.thresholds.detach().cpu().numpy().tolist()\n",
    "\n",
    "        # Save config for reproducibility\n",
    "        config = {\n",
    "            \"model_type\": \"distilbert\",\n",
    "            \"num_labels\": self.classifier.out_features,\n",
    "            \"temperature\": getattr(self, \"temperature\", None),\n",
    "            \"thresholds\": thresholds,\n",
    "            \"num_layers\": self.num_layers\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(save_directory, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        print(f\"Model saved to {save_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fc04255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def train_hard_pruning_model(soft_model, train_loader, val_loader, num_epochs=1, lr=5e-5, device='cuda'):\n",
    "    \n",
    "    # Convert soft model to hard pruning model\n",
    "    hard_model = DistilBertWithHardPruning(\n",
    "        pretrained_soft_model=deepcopy(soft_model)\n",
    "    )\n",
    "    hard_model.to(device)\n",
    "\n",
    "    # Freeze threshold parameters\n",
    "    hard_model.threshold_layer.thresholds.requires_grad = False\n",
    "\n",
    "    # Set up optimizer for all other trainable parameters\n",
    "    optimizer = AdamW(\n",
    "        filter(lambda p: p.requires_grad, hard_model.parameters()), \n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        hard_model.train()\n",
    "        train_loss = 0.0\n",
    "       \n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "\n",
    "\n",
    "        for batch in train_loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = hard_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            if torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "            clip_grad_norm_(hard_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            # Update tqdm progress bar with current loss\n",
    "            train_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        hard_model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = total = 0\n",
    "        # Create validation loop with tqdm\n",
    "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validate]\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loop:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = hard_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                logits = outputs.logits\n",
    "                loss = outputs.loss\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                # Update tqdm progress bar with current loss and accuracy\n",
    "                val_loop.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{correct/total:.4f}\")\n",
    "        \n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = deepcopy(hard_model.state_dict())\n",
    "\n",
    "    # Load best model state before returning\n",
    "    hard_model.load_state_dict(best_model_state)\n",
    "    return hard_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0032c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07362a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Train Loss: 0.2022 | Val Loss: 0.2645 | Val Acc: 0.9327\n"
     ]
    }
   ],
   "source": [
    "# Assume you have the tokenizer and dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load pretrained soft-pruned model\n",
    "soft_model = DistilBertWithThresholdPruning(MODEL_PATH_2)\n",
    "soft_model.threshold_layer.thresholds.requires_grad = False\n",
    "\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "# Train the hard-pruning model\n",
    "final_model = train_hard_pruning_model(\n",
    "    soft_model=soft_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=1,\n",
    "    lr=5e-5,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60ba95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ag_news_distilbert_hard\n"
     ]
    }
   ],
   "source": [
    "final_model.save_pretrained(MODEL_PATH_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "969dd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def save_predictions_to_csv(model, dataloader, tokenizer, output_csv, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            # Recompute hard pruning mask (same as model.forward)\n",
    "            attention_outputs = model.distilbert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_attentions=True,\n",
    "                return_dict=True\n",
    "            ).attentions\n",
    "\n",
    "            final_layer_attention = attention_outputs[-1]\n",
    "            token_scores = final_layer_attention.mean(dim=1).mean(dim=1)\n",
    "            threshold = model.threshold_layer(model.num_layers - 1)\n",
    "            mask = (token_scores > threshold).float()\n",
    "\n",
    "            # Always keep CLS\n",
    "            cls = torch.ones(mask.size(0), 1).to(device)\n",
    "            mask = torch.cat([cls, mask[:, 1:]], dim=1)\n",
    "\n",
    "            for i in range(input_ids.size(0)):\n",
    "                tokens = input_ids[i]\n",
    "                input_sentence = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "                kept_indices = torch.where(mask[i] > 0.5)[0]\n",
    "                kept_tokens = tokens[kept_indices]\n",
    "                pruned_sentence = tokenizer.decode(kept_tokens, skip_special_tokens=True)\n",
    "\n",
    "                rows.append({\n",
    "                    \"input_sentence\": input_sentence,\n",
    "                    \"remaining_sentence\": pruned_sentence,\n",
    "                    \"true_label\": labels[i].item(),\n",
    "                    \"predicted_label\": predictions[i].item()\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved results to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d3dc5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 950/950 [05:26<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to predictions_with_pruned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer (same one used during training)\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "\n",
    "# Assume you have: `final_model`, `test_loader`, `DEVICE`\n",
    "save_predictions_to_csv(\n",
    "    model=final_model,\n",
    "    dataloader=test_loader,\n",
    "    tokenizer=tokenizer,\n",
    "    output_csv=\"predictions_with_pruned.csv\",\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8ed55",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1fc8d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "| Metric            |   Value |\n",
      "+===================+=========+\n",
      "| Accuracy          |  0.9363 |\n",
      "+-------------------+---------+\n",
      "| Precision (Macro) |  0.9374 |\n",
      "+-------------------+---------+\n",
      "| Recall (Macro)    |  0.9363 |\n",
      "+-------------------+---------+\n",
      "| F1-Score (Macro)  |  0.9364 |\n",
      "+-------------------+---------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.97      0.92      0.95      1900\n",
      "      Sports       0.97      0.98      0.98      1900\n",
      "    Business       0.92      0.89      0.91      1900\n",
      "    Sci/Tech       0.88      0.94      0.91      1900\n",
      "\n",
      "    accuracy                           0.94      7600\n",
      "   macro avg       0.94      0.94      0.94      7600\n",
      "weighted avg       0.94      0.94      0.94      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "# AG News class labels\n",
    "LABELS = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "# Function to evaluate the model on the test dataset\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "# Evaluate the model\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "true_labels, predicted_labels = evaluate_model(final_model, test_loader, DEVICE)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average=\"macro\")\n",
    "recall = recall_score(true_labels, predicted_labels, average=\"macro\")\n",
    "f1 = f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "\n",
    "# Print results as a table\n",
    "results = [\n",
    "    [\"Metric\", \"Value\"],\n",
    "    [\"Accuracy\", f\"{accuracy:.4f}\"],\n",
    "    [\"Precision (Macro)\", f\"{precision:.4f}\"],\n",
    "    [\"Recall (Macro)\", f\"{recall:.4f}\"],\n",
    "    [\"F1-Score (Macro)\", f\"{f1:.4f}\"]\n",
    "]\n",
    "\n",
    "print(tabulate(results, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "\n",
    "# Optional: Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=LABELS.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b718c",
   "metadata": {},
   "source": [
    "### Visualizing the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7853bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds: [0.07640352 0.09950283 0.08569011 0.06723312 0.12944147 0.19382311]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_thresholds(model):\n",
    "    \"\"\"\n",
    "    Visualize the thresholds of each layer in the DistilBertWithThresholdPruning model.\n",
    "    \n",
    "    Args:\n",
    "        model (DistilBertWithThresholdPruning): The model with learned thresholds.\n",
    "    \"\"\"\n",
    "    # Get the thresholds as a numpy array\n",
    "    thresholds = model.get_thresholds()\n",
    "    print(\"Thresholds:\", thresholds)\n",
    "    \n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.arange(len(thresholds)), thresholds, color='skyblue')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('Threshold Value')\n",
    "    plt.title('Thresholds for Each Layer')\n",
    "    plt.xticks(np.arange(len(thresholds)))\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `threshold_model` is an instance of DistilBertWithThresholdPruning\n",
    "visualize_thresholds(threshold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d50fa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2324d831",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbf9a233",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7a1428",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a7b8105",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220500fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeadeb1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d67d8ec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
