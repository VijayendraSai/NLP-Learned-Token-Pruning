{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d861a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/env_NLP/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast, \n",
    "    DistilBertConfig,\n",
    "    DistilBertModel,\n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3016c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LR = 1e-5\n",
    "EPOCHS = 3\n",
    "MODEL_PATH_1 = \"imdb_distilbert_finetuned\"\n",
    "MODEL_PATH_2 = \"imdb_distilbert_soft\"\n",
    "MODEL_PATH_3 = \"imdb_distilbert_hard\"\n",
    "MAX_LENGTH = 512\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a5e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## device\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.backends.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "# DEVICE = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63952b36",
   "metadata": {},
   "source": [
    "### phase 1: finetune the model on imdb dataset for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa6edcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, tokenizer, batch_size,  max_length=MAX_LENGTH,size=None):\n",
    "    # if size is None:\n",
    "    #     dataset = load_dataset(dataset_name, split=split)\n",
    "    # else:\n",
    "    #     dataset = load_dataset(dataset_name, split=split).shuffle(seed=42).select(range(size))\n",
    "    def preprocess(examples):\n",
    "        enc = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=max_length)\n",
    "        enc['labels'] = examples['label']\n",
    "        return enc\n",
    "    dataset = dataset.map(preprocess, batched=True)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    # return DataLoader(dataset, batch_size=batch_size, shuffle=(split=='train'))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332299b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    # Extract logits from the tuple\n",
    "    logits = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    \n",
    "    # Get predicted class labels\n",
    "    preds = logits.argmax(-1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    labels = pred.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    print(f'accuracy: {acc}, f1: {f1}, precision: {precision}, recall: {recall}')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4896101",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9af57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_dataset = get_dataloader('imdb', tokenizer,  32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da8e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9784a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n,batch in enumerate(imdb_dataset):\n",
    "#     print(batch)\n",
    "#     if n==0:\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e60b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration and enable output_attentions\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Load the model with the configuration\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',config=config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d104eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b481ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting training and validation and testing datasets\n",
    "\n",
    "# Load the full training dataset\n",
    "full_train_dataset = load_dataset('imdb', split='train').shuffle(seed=42)\n",
    "\n",
    "# Split the training dataset into train and validation sets\n",
    "train_size = 0.9  # 90% for training, 10% for validation\n",
    "split_data = full_train_dataset.train_test_split(test_size=1-train_size, seed=42)\n",
    "train_data = split_data['train']\n",
    "val_data = split_data['test']\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = load_dataset('imdb', split='test')\n",
    "\n",
    "full_train_dataset, \n",
    "\n",
    "# # Preprocess train, validation, and test datasets\n",
    "train_dataset = preprocess_data(train_data, tokenizer, BATCH_SIZE)\n",
    "val_dataset = preprocess_data(val_data, tokenizer, BATCH_SIZE)\n",
    "test_dataset = preprocess_data(test_data, tokenizer, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a430d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c91c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,  # Set to True if you want to push to Hugging Face Hub\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516a0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065aae4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4218' max='4218' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4218/4218 1:18:16, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.210475</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>0.917172</td>\n",
       "      <td>0.913113</td>\n",
       "      <td>0.921266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.320689</td>\n",
       "      <td>0.931200</td>\n",
       "      <td>0.931746</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.952922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.918, f1: 0.9171717171717172, precision: 0.913113435237329, recall: 0.9212662337662337\n",
      "accuracy: 0.9256, f1: 0.9249394673123487, precision: 0.9197431781701445, recall: 0.9301948051948052\n",
      "accuracy: 0.9312, f1: 0.9317460317460318, precision: 0.9114906832298136, recall: 0.952922077922078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4218, training_loss=0.1790976125178192, metrics={'train_runtime': 4698.2151, 'train_samples_per_second': 14.367, 'train_steps_per_second': 0.898, 'total_flos': 8936780582928384.0, 'train_loss': 0.1790976125178192, 'epoch': 2.9984})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a47c0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to imdb_distilbert_finetuned\n"
     ]
    }
   ],
   "source": [
    "model_path = MODEL_PATH_1\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13896dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9312, f1: 0.9317460317460318, precision: 0.9114906832298136, recall: 0.952922077922078\n",
      "Evaluation results: {'eval_loss': 0.3206891417503357, 'eval_accuracy': 0.9312, 'eval_f1': 0.9317460317460318, 'eval_precision': 0.9114906832298136, 'eval_recall': 0.952922077922078, 'eval_runtime': 46.6019, 'eval_samples_per_second': 53.646, 'eval_steps_per_second': 6.716, 'epoch': 2.9984}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99447db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review: 'This movie was fantastic! The acting was superb and the plot kept me engaged throughout.'\n",
      "Predicted sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Example inference function\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH, padding=\"max_length\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    return \"Positive\" if predicted_class == 1 else \"Negative\"\n",
    "\n",
    "# Test with a sample review\n",
    "sample_review = \"This movie was fantastic! The acting was superb and the plot kept me engaged throughout.\"\n",
    "sentiment = predict_sentiment(sample_review)\n",
    "print(f\"Sample review: '{sample_review}'\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73981bf",
   "metadata": {},
   "source": [
    "### phase 2: soft pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7076fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bz2 import compress\n",
    "class ThresholdLayer(nn.Module):\n",
    "    \"\"\"Layer that learns threshold values for attention-based token pruning\"\"\"\n",
    "    def __init__(self, num_layers, init_threshold=0.02):\n",
    "        super(ThresholdLayer, self).__init__()\n",
    "        self.thresholds = nn.Parameter(torch.ones(num_layers) * init_threshold)\n",
    "        \n",
    "    def forward(self, layer_idx):\n",
    "        return self.thresholds[layer_idx]\n",
    "\n",
    "class DistilBertWithThresholdPruning(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_labels=2, temperature=1e-3, init_threshold=0.01, lambda_reg=1e-5):\n",
    "        super(DistilBertWithThresholdPruning, self).__init__()\n",
    "        \n",
    "        # Load the fine-tuned DistilBERT model\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\n",
    "            pretrained_model_path, \n",
    "            output_attentions=True,  # Important to get attention scores\n",
    "            attn_implementation='eager',  # Use softmax for attention\n",
    "        )\n",
    "        \n",
    "        # Number of transformer layers in DistilBERT\n",
    "        self.num_layers = len(self.distilbert.transformer.layer)\n",
    "        \n",
    "        # Create the threshold layer\n",
    "        self.threshold_layer = ThresholdLayer(\n",
    "            num_layers=self.num_layers,\n",
    "            init_threshold=init_threshold\n",
    "        )\n",
    "        \n",
    "        # Temperature for sigmoid scaling\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Regularization coefficient\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "        # Classification head\n",
    "        self.pre_classifier = nn.Linear(768, 768)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "        \n",
    "\n",
    "    \n",
    "    def prune_tokens(self, hidden_states,  attn_mask):\n",
    "        \"\"\"Apply token pruning based on attention mask\"\"\"\n",
    "        # For training phase: soft masking using the attention scores\n",
    "        # We multiply by the mask which will downweight less important tokens\n",
    "        # hidden_states: [batch_size, seq_len, hidden_size]\n",
    "        # attn_mask: [batch_size, seq_len]\n",
    "        \n",
    "        # Expand mask to match hidden states dimensions\n",
    "        expanded_mask = attn_mask.unsqueeze(-1).expand_as(hidden_states)\n",
    "        \n",
    "        # Apply mask to hidden states\n",
    "        masked_hidden_states = hidden_states * expanded_mask\n",
    "        \n",
    "        return masked_hidden_states\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Get DistilBERT outputs with attention scores\n",
    "        outputs = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=True,  # Important to get attention scores\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Get sequence output and attention scores\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "        attention_outputs = outputs.attentions  # Tuple of tensors [batch_size, num_heads, seq_len, seq_len]\n",
    "        \n",
    "        # Apply pruning using attention scores\n",
    "        reg_loss = 0.0\n",
    "        \n",
    "        # Process each layer's attention\n",
    "        for layer_idx, attention in enumerate(attention_outputs):\n",
    "            # Average attention scores across heads to get token importance\n",
    "            # [batch_size, seq_len, seq_len] -> [batch_size, seq_len]\n",
    "            token_scores = attention.mean(dim=1).mean(dim=1)  \n",
    "            \n",
    "            # Get threshold for this layer\n",
    "            threshold = self.threshold_layer(layer_idx)\n",
    "            \n",
    "            # Create soft mask\n",
    "            soft_mask = torch.sigmoid((token_scores - threshold) / self.temperature)\n",
    "            \n",
    "            # Add regularization: encourage fewer retained tokens\n",
    "            reg_loss += soft_mask.mean()\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Use [CLS] token for classification (first token)\n",
    "        pooled_output = sequence_output[:, 0]  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Classification head\n",
    "        pooled_output = self.pre_classifier(pooled_output)\n",
    "        pooled_output = nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "            loss += self.lambda_reg * reg_loss\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )\n",
    "\n",
    "    def fix_thresholds(self):\n",
    "        \"\"\"Fix the threshold values after training\"\"\"\n",
    "        self.threshold_layer.thresholds.requires_grad = False\n",
    "        \n",
    "    def get_thresholds(self):\n",
    "        \"\"\"Get the learned threshold values for each layer\"\"\"\n",
    "        return self.threshold_layer.thresholds.detach().cpu().numpy()\n",
    "    \n",
    "    def save_pretrained(self, save_directory):\n",
    "        \"\"\"Save model to the specified directory in a format compatible with HF\"\"\"\n",
    "        if not os.path.exists(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "        \n",
    "        # Save the model weights\n",
    "        torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "        \n",
    "        # Save configuration\n",
    "        config = {\n",
    "            \"model_type\": \"distilbert\",\n",
    "            \"num_labels\": 2,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"thresholds\": self.get_thresholds().tolist(),\n",
    "            \"num_layers\": self.num_layers,\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(save_directory, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_path, num_labels=2, temperature=1e-3, init_threshold=0.01, lambda_reg=1e-5):\n",
    "        \"\"\"Load model from pretrained directory\"\"\"\n",
    "        # Load config from saved model\n",
    "        config_path = os.path.join(pretrained_model_path, \"config.json\")\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "            \n",
    "            # Get parameters from config\n",
    "            # init_threshold = 0.01  # default\n",
    "             # Get parameters from config\n",
    "            init_threshold = config.get(\"thresholds\", [init_threshold])[0]\n",
    "            num_labels = config.get(\"num_labels\", num_labels)\n",
    "            temperature = config.get(\"temperature\", temperature)\n",
    "            \n",
    "        \n",
    "        # Create a new instance\n",
    "        model = cls(\n",
    "            pretrained_model_path,\n",
    "            num_labels=num_labels,\n",
    "            temperature=temperature,\n",
    "            init_threshold=init_threshold,\n",
    "            lambda_reg=lambda_reg\n",
    "        )\n",
    "        \n",
    "        # Load the state dict if it exists\n",
    "        model_path = os.path.join(pretrained_model_path, \"pytorch_model.bin\")\n",
    "        if os.path.exists(model_path):\n",
    "            model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091febcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regex import B\n",
    "\n",
    "\n",
    "def train_threshold_model(pretrained_model_path, dataset, tokenizer):\n",
    "    \"\"\"Train the threshold-based model\"\"\"\n",
    "    # Create model\n",
    "    model = DistilBertWithThresholdPruning(\n",
    "        pretrained_model_path=pretrained_model_path,\n",
    "        num_labels=2,\n",
    "        temperature=1e-3,\n",
    "        init_threshold=0.02,\n",
    "        lambda_reg=1e-5\n",
    "    )\n",
    "    \n",
    "    # Training parameters\n",
    "    learning_rate = 1e-5\n",
    "    num_epochs = 3\n",
    "    batch_size = BATCH_SIZE\n",
    "    device = DEVICE\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create DataLoader for training set\n",
    "    train_dataloader = train_dataset\n",
    "    \n",
    "    torch.mps.empty_cache()\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            # Prepare batch\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "             # Clear attention scores to free memory\n",
    "            del outputs.attentions\n",
    "            torch.mps.empty_cache()  # Clear memory on MPS backend\n",
    "\n",
    "            \n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Avg loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Fix thresholds after training\n",
    "    model.fix_thresholds()\n",
    "    \n",
    "    # Print learned thresholds\n",
    "    thresholds = model.get_thresholds()\n",
    "    print(f\"Learned thresholds: {thresholds}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db14558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Avg loss: 0.0803\n",
      "Epoch 2/3 - Avg loss: 0.0520\n",
      "Epoch 3/3 - Avg loss: 0.0366\n",
      "Learned thresholds: [0.10545765 0.08017303 0.07289841 0.05522738 0.11968768 0.15995482]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Path to your fine-tuned model from previous step\n",
    "pretrained_model_path = MODEL_PATH_1\n",
    "\n",
    "# Train threshold model\n",
    "threshold_model = train_threshold_model(\n",
    "    pretrained_model_path=pretrained_model_path,\n",
    "    dataset=train_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9fd8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_model.save_pretrained(MODEL_PATH_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78874f",
   "metadata": {},
   "source": [
    "### phase 3: fixing thresholds and training for hard pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "664a00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertWithHardPruning(nn.Module):\n",
    "    def __init__(self, pretrained_soft_model: DistilBertWithThresholdPruning):\n",
    "        super().__init__()\n",
    "\n",
    "        # Clone the architecture and load soft-pruned weights\n",
    "        self.distilbert = pretrained_soft_model.distilbert\n",
    "        self.num_layers = pretrained_soft_model.num_layers\n",
    "        self.threshold_layer = pretrained_soft_model.threshold_layer  # frozen\n",
    "        self.temperature = pretrained_soft_model.temperature\n",
    "        self.pre_classifier = pretrained_soft_model.pre_classifier\n",
    "        self.dropout = pretrained_soft_model.dropout\n",
    "        self.classifier = pretrained_soft_model.classifier\n",
    "\n",
    "        # Freeze thresholds\n",
    "        self.threshold_layer.thresholds.requires_grad = False\n",
    "\n",
    "        # self.\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state  # [B, S, H]\n",
    "        attention_outputs = outputs.attentions \n",
    "        for layer_idx, attention in enumerate(attention_outputs):\n",
    "            \n",
    "            token_scores = attention.mean(dim=1).mean(dim=1)  # [B, seq_len]\n",
    "            threshold = self.threshold_layer(layer_idx)\n",
    "            hard_mask = (token_scores > threshold).float()  # binary mask\n",
    "            # print(\"Hard mask shape:\", hard_mask.shape)\n",
    "\n",
    "            # Always keep [CLS] token (position 0)\n",
    "            cls_token = torch.ones(hard_mask.size(0), 1, device=hard_mask.device)\n",
    "            hard_mask = torch.cat([cls_token, hard_mask[:, 1:]], dim=1)\n",
    "\n",
    "            # Expand and apply pruning mask\n",
    "            expanded_mask = hard_mask.unsqueeze(-1).expand_as(hidden_states)\n",
    "            hidden_states = hidden_states * expanded_mask\n",
    "\n",
    "        pooled_output = hidden_states[:, 0]  # Use CLS token for classification\n",
    "        pooled_output = self.pre_classifier(pooled_output)\n",
    "        pooled_output = nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )\n",
    "            \n",
    "    \n",
    "    def save_pretrained(self, save_directory):\n",
    "       \n",
    "        if not os.path.exists(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "\n",
    "        # Save model state dict\n",
    "        torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "\n",
    "        # Save thresholds (frozen from soft model)\n",
    "        thresholds = self.threshold_layer.thresholds.detach().cpu().numpy().tolist()\n",
    "\n",
    "        # Save config for reproducibility\n",
    "        config = {\n",
    "            \"model_type\": \"distilbert\",\n",
    "            \"num_labels\": self.classifier.out_features,\n",
    "            \"temperature\": getattr(self, \"temperature\", None),\n",
    "            \"thresholds\": thresholds,\n",
    "            \"num_layers\": self.num_layers\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(save_directory, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        print(f\"Model saved to {save_directory}\")\n",
    "        \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_path):\n",
    "        # Load config from saved model\n",
    "        config_path = os.path.join(pretrained_model_path, \"config.json\")\n",
    "        if not os.path.exists(config_path):\n",
    "            raise FileNotFoundError(f\"Config file not found in {config_path}\")\n",
    "\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        # Create a new instance of the soft-pruned model\n",
    "        soft_model = DistilBertWithThresholdPruning.from_pretrained(pretrained_model_path)\n",
    "\n",
    "        # Create a new instance of the hard-pruned model\n",
    "        hard_model = cls(pretrained_soft_model=soft_model)\n",
    "\n",
    "        # Load the state dict\n",
    "        model_path = os.path.join(pretrained_model_path, \"pytorch_model.bin\")\n",
    "        if os.path.exists(model_path):\n",
    "            hard_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Model weights not found in {model_path}\")\n",
    "\n",
    "        return hard_model\n",
    "    \n",
    "    def get_thresholds(self):\n",
    "        \"\"\"Get the learned threshold values for each layer.\"\"\"\n",
    "        return self.threshold_layer.thresholds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fc04255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def train_hard_pruning_model(soft_model, train_loader, val_loader, num_epochs=3, lr=5e-5, device='cuda'):\n",
    "    \n",
    "    # Convert soft model to hard pruning model\n",
    "    hard_model = DistilBertWithHardPruning(\n",
    "        pretrained_soft_model=deepcopy(soft_model)\n",
    "    )\n",
    "    hard_model.to(device)\n",
    "\n",
    "    # Freeze threshold parameters\n",
    "    hard_model.threshold_layer.thresholds.requires_grad = False\n",
    "\n",
    "    # Set up optimizer for all other trainable parameters\n",
    "    optimizer = AdamW(\n",
    "        filter(lambda p: p.requires_grad, hard_model.parameters()), \n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        hard_model.train()\n",
    "        train_loss = 0.0\n",
    "       \n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "\n",
    "\n",
    "        for batch in train_loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = hard_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            if torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "            clip_grad_norm_(hard_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            # Update tqdm progress bar with current loss\n",
    "            train_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        hard_model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = total = 0\n",
    "        # Create validation loop with tqdm\n",
    "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validate]\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loop:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = hard_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                logits = outputs.logits\n",
    "                loss = outputs.loss\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                # Update tqdm progress bar with current loss and accuracy\n",
    "                val_loop.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{correct/total:.4f}\")\n",
    "        \n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = deepcopy(hard_model.state_dict())\n",
    "\n",
    "    # Load best model state before returning\n",
    "    hard_model.load_state_dict(best_model_state)\n",
    "    return hard_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0032c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07362a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Train Loss: 0.1170 | Val Loss: 0.5397 | Val Acc: 0.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | Train Loss: 0.0903 | Val Loss: 0.5817 | Val Acc: 0.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | Train Loss: 0.0798 | Val Loss: 0.4352 | Val Acc: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Assume you have the tokenizer and dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load pretrained soft-pruned model\n",
    "soft_model = DistilBertWithThresholdPruning(MODEL_PATH_2)\n",
    "soft_model.threshold_layer.thresholds.requires_grad = False\n",
    "\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "# Train the hard-pruning model\n",
    "final_model = train_hard_pruning_model(\n",
    "    soft_model=soft_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=3,\n",
    "    lr=5e-5,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60ba95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to imdb_distilbert_hard\n"
     ]
    }
   ],
   "source": [
    "final_model.save_pretrained(MODEL_PATH_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "969dd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def save_predictions_to_csv(model, dataloader, tokenizer, output_csv, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            # Recompute hard pruning mask (same as model.forward)\n",
    "            attention_outputs = model.distilbert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_attentions=True,\n",
    "                return_dict=True\n",
    "            ).attentions\n",
    "\n",
    "            final_layer_attention = attention_outputs[-1]\n",
    "            token_scores = final_layer_attention.mean(dim=1).mean(dim=1)\n",
    "            threshold = model.threshold_layer(model.num_layers - 1)\n",
    "            mask = (token_scores > threshold).float()\n",
    "\n",
    "            # Always keep CLS\n",
    "            cls = torch.ones(mask.size(0), 1).to(device)\n",
    "            mask = torch.cat([cls, mask[:, 1:]], dim=1)\n",
    "\n",
    "            for i in range(input_ids.size(0)):\n",
    "                tokens = input_ids[i]\n",
    "                input_sentence = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "                kept_indices = torch.where(mask[i] > 0.5)[0]\n",
    "                kept_tokens = tokens[kept_indices]\n",
    "                pruned_sentence = tokenizer.decode(kept_tokens, skip_special_tokens=True)\n",
    "\n",
    "                rows.append({\n",
    "                    \"input_sentence\": input_sentence,\n",
    "                    \"remaining_sentence\": pruned_sentence,\n",
    "                    \"true_label\": labels[i].item(),\n",
    "                    \"predicted_label\": predictions[i].item()\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved results to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d3dc5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3125/3125 [17:16<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to predictions_with_pruned.csv\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer (same one used during training)\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "\n",
    "# Assume you have: `final_model`, `test_loader`, `DEVICE`\n",
    "save_predictions_to_csv(\n",
    "    model=final_model,\n",
    "    dataloader=test_loader,\n",
    "    tokenizer=tokenizer,\n",
    "    output_csv=\"predictions_with_pruned.csv\",\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e932b",
   "metadata": {},
   "source": [
    "### Visualizing the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1e7ea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "## load the model\n",
    "threshold_model = MODEL_PATH_2  # Replace with the actual path if different\n",
    "\n",
    "# Load the final model\n",
    "threshold_model = DistilBertWithHardPruning.from_pretrained(threshold_model)\n",
    "\n",
    "# Load the tokenizer (if needed)\n",
    "# tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "threshold_model.to(DEVICE)\n",
    "\n",
    "print(\"Final model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1c8fad",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8165c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "| Metric    |   Value |\n",
      "+===========+=========+\n",
      "| Accuracy  |  0.9017 |\n",
      "+-----------+---------+\n",
      "| Precision |  0.9114 |\n",
      "+-----------+---------+\n",
      "| Recall    |  0.89   |\n",
      "+-----------+---------+\n",
      "| F1-Score  |  0.9006 |\n",
      "+-----------+---------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.91      0.90     12500\n",
      "    Positive       0.91      0.89      0.90     12500\n",
      "\n",
      "    accuracy                           0.90     25000\n",
      "   macro avg       0.90      0.90      0.90     25000\n",
      "weighted avg       0.90      0.90      0.90     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Function to evaluate the model on the test dataset\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "# Evaluate the model\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "true_labels, predicted_labels = evaluate_model(final_model, test_loader, DEVICE)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average=\"binary\")\n",
    "recall = recall_score(true_labels, predicted_labels, average=\"binary\")\n",
    "f1 = f1_score(true_labels, predicted_labels, average=\"binary\")\n",
    "\n",
    "# Print results as a table\n",
    "results = [\n",
    "    [\"Metric\", \"Value\"],\n",
    "    [\"Accuracy\", f\"{accuracy:.4f}\"],\n",
    "    [\"Precision\", f\"{precision:.4f}\"],\n",
    "    [\"Recall\", f\"{recall:.4f}\"],\n",
    "    [\"F1-Score\", f\"{f1:.4f}\"]\n",
    "]\n",
    "\n",
    "print(tabulate(results, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "\n",
    "# Optional: Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f090e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds: [0.10545765 0.08017303 0.07289841 0.05522738 0.11968768 0.15995482]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_thresholds(model):\n",
    "    \"\"\"\n",
    "    Visualize the thresholds of each layer in the DistilBertWithThresholdPruning model.\n",
    "    \n",
    "    Args:\n",
    "        model (DistilBertWithThresholdPruning): The model with learned thresholds.\n",
    "    \"\"\"\n",
    "    # Get the thresholds as a numpy array\n",
    "    thresholds = model.get_thresholds()\n",
    "    print(\"Thresholds:\", thresholds)\n",
    "    \n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.arange(len(thresholds)), thresholds, color='skyblue')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel('Threshold Value')\n",
    "    plt.title('Thresholds for Each Layer')\n",
    "    plt.xticks(np.arange(len(thresholds)))\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `threshold_model` is an instance of DistilBertWithThresholdPruning\n",
    "visualize_thresholds(threshold_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324d831",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daf908de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
